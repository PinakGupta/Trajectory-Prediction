{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmrnMKIgW5FI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run in a Colab cell\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFBqph9sW7us",
        "outputId": "410b1878-0e5b-4990-ef15-90729d742845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17496, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 17496 (delta 2), reused 0 (delta 0), pack-reused 17491 (from 3)\u001b[K\n",
            "Receiving objects: 100% (17496/17496), 16.54 MiB | 20.33 MiB/s, done.\n",
            "Resolving deltas: 100% (11990/11990), done.\n",
            "/content/yolov5\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (11.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.15.3)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
            "Collecting ultralytics>=8.2.34 (from -r requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.3.161-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (75.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.6.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.34->-r requirements.txt (line 18))\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.3.161-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 thop-0.1.1.post2209072238 ultralytics-8.3.161 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision\n",
        "!pip install opencv-python-headless\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "bYNUh_7LXdaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hSql0bHLa0b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "7H2LldNza5xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Load the model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/drive/MyDrive/test_model/best030422.pt', force_reload=True)"
      ],
      "metadata": {
        "id": "gAkDEah_a8QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "img_path = '/content/drive/MyDrive/test_model/tennis_ball.jpg'\n",
        "results = model(img_path)\n",
        "\n",
        "# Show results\n",
        "results.print()\n",
        "results.show()  # Opens image with detections\n",
        "\n",
        "# Display inline\n",
        "plt.imshow(Image.open(img_path))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DU7AS0u4a-iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate torchvision"
      ],
      "metadata": {
        "id": "KWrQRo16bCWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3D kalman filter trajectory code with depth estimation using MiDaS_small\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from models.common import DetectMultiBackend\n",
        "from utils.dataloaders import LoadImages\n",
        "from utils.general import (check_img_size, non_max_suppression, xyxy2xywh, increment_path)\n",
        "from utils.torch_utils import select_device\n",
        "\n",
        "# Install required packages for Google Colab\n",
        "try:\n",
        "    import transformers\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    subprocess.check_call(['pip', 'install', 'transformers'])\n",
        "    import transformers\n",
        "\n",
        "def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):\n",
        "    if ratio_pad is None:\n",
        "        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])\n",
        "        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2\n",
        "    else:\n",
        "        gain = ratio_pad[0][0]\n",
        "        pad = ratio_pad[1]\n",
        "\n",
        "    coords[:, [0, 2]] -= pad[0]\n",
        "    coords[:, [1, 3]] -= pad[1]\n",
        "    coords[:, :4] /= gain\n",
        "    return coords\n",
        "\n",
        "def clip_coords(boxes, shape):\n",
        "    if isinstance(boxes, torch.Tensor):\n",
        "        boxes[:, 0].clamp_(0, shape[1])\n",
        "        boxes[:, 1].clamp_(0, shape[0])\n",
        "        boxes[:, 2].clamp_(0, shape[1])\n",
        "        boxes[:, 3].clamp_(0, shape[0])\n",
        "    else:\n",
        "        boxes[:, [0, 2]] = boxes[:, [0, 2]].clip(0, shape[1])\n",
        "        boxes[:, [1, 3]] = boxes[:, [1, 3]].clip(0, shape[0])\n",
        "\n",
        "# Depth estimation using MiDaS model\n",
        "class DepthEstimator:\n",
        "    def __init__(self, device='cpu'):\n",
        "        self.device = device\n",
        "        # Load MiDaS model for depth estimation\n",
        "        self.model = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')\n",
        "        self.model.to(device)\n",
        "        self.model.eval()\n",
        "\n",
        "        # Load transforms\n",
        "        midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')\n",
        "        self.transform = midas_transforms.small_transform\n",
        "\n",
        "    def estimate_depth(self, image):\n",
        "        \"\"\"Estimate depth map from RGB image\"\"\"\n",
        "        # Preprocess image\n",
        "        input_batch = self.transform(image).to(self.device)\n",
        "\n",
        "        # Predict depth\n",
        "        with torch.no_grad():\n",
        "            prediction = self.model(input_batch)\n",
        "            prediction = torch.nn.functional.interpolate(\n",
        "                prediction.unsqueeze(1),\n",
        "                size=image.shape[:2],\n",
        "                mode=\"bicubic\",\n",
        "                align_corners=False,\n",
        "            ).squeeze()\n",
        "\n",
        "        # Convert to numpy and normalize\n",
        "        depth_map = prediction.cpu().numpy()\n",
        "        return depth_map\n",
        "\n",
        "    def get_depth_at_point(self, depth_map, x, y):\n",
        "        \"\"\"Get depth value at specific pixel coordinates\"\"\"\n",
        "        if 0 <= y < depth_map.shape[0] and 0 <= x < depth_map.shape[1]:\n",
        "            return depth_map[int(y), int(x)]\n",
        "        return 0\n",
        "\n",
        "# 3D Kalman Filter with gravity modeling\n",
        "class KalmanFilter3D:\n",
        "    def __init__(self, x, y, z, dt=1.0, g=0.5):\n",
        "        self.dt = dt\n",
        "        self.g = g\n",
        "        # State: [x, y, z, vx, vy, vz]\n",
        "        self.state = np.array([x, y, z, 0, 0, 0], dtype=np.float32)\n",
        "\n",
        "        # State transition matrix (6x6)\n",
        "        self.F = np.array([\n",
        "            [1, 0, 0, dt, 0, 0],\n",
        "            [0, 1, 0, 0, dt, 0],\n",
        "            [0, 0, 1, 0, 0, dt],\n",
        "            [0, 0, 0, 1, 0, 0],\n",
        "            [0, 0, 0, 0, 1, 0],\n",
        "            [0, 0, 0, 0, 0, 1]\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "        # Measurement matrix (3x6) - we observe x, y, z\n",
        "        self.H = np.array([\n",
        "            [1, 0, 0, 0, 0, 0],\n",
        "            [0, 1, 0, 0, 0, 0],\n",
        "            [0, 0, 1, 0, 0, 0]\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "        # Process noise covariance (6x6)\n",
        "        self.Q = np.eye(6, dtype=np.float32) * 0.01\n",
        "\n",
        "        # Measurement noise covariance (3x3)\n",
        "        self.R = np.array([\n",
        "            [10, 0, 0],\n",
        "            [0, 10, 0],\n",
        "            [0, 0, 50]  # Higher noise for depth\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "        # State covariance (6x6)\n",
        "        self.P = np.eye(6, dtype=np.float32) * 100\n",
        "\n",
        "    def predict(self):\n",
        "        # State prediction\n",
        "        self.state = self.F @ self.state\n",
        "        # Apply gravity effects (assuming y is vertical axis)\n",
        "        self.state[1] += 0.5 * self.g * self.dt**2  # Update y position\n",
        "        self.state[4] += self.g * self.dt           # Update y velocity\n",
        "        # Covariance prediction\n",
        "        self.P = self.F @ self.P @ self.F.T + self.Q\n",
        "        return self.state[0], self.state[1], self.state[2]\n",
        "\n",
        "    def correct(self, x, y, z):\n",
        "        z_measurement = np.array([x, y, z], dtype=np.float32)\n",
        "        # Measurement residual\n",
        "        y_residual = z_measurement - self.H @ self.state\n",
        "        # Residual covariance\n",
        "        S = self.H @ self.P @ self.H.T + self.R\n",
        "        # Kalman gain\n",
        "        K = self.P @ self.H.T @ np.linalg.inv(S)\n",
        "        # State update\n",
        "        self.state = self.state + K @ y_residual\n",
        "        # Covariance update\n",
        "        I = np.eye(6, dtype=np.float32)\n",
        "        self.P = (I - K @ self.H) @ self.P\n",
        "\n",
        "def run(\n",
        "    weights,\n",
        "    source,\n",
        "    data,\n",
        "    imgsz,\n",
        "    conf_thres,\n",
        "    iou_thres,\n",
        "    max_det,\n",
        "    device,\n",
        "    project,\n",
        "    name,\n",
        "    exist_ok,\n",
        "    half,\n",
        "    dnn,\n",
        "    g=0.5,\n",
        "    early_pred_frame=10,\n",
        "    depth_scale=1000.0\n",
        "):\n",
        "    source = str(source)\n",
        "    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Initialize data collection\n",
        "    actual_trajectory_3d = []\n",
        "    predicted_full_trajectory_3d = []\n",
        "    frame_height = None\n",
        "    triggered = False\n",
        "\n",
        "    # Device and model\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
        "    stride, names, pt = model.stride, model.names, model.pt\n",
        "    imgsz = check_img_size(imgsz, s=stride)\n",
        "\n",
        "    # Initialize depth estimator\n",
        "    print(\"Loading depth estimation model...\")\n",
        "    depth_estimator = DepthEstimator(device=device)\n",
        "    print(\"Depth estimation model loaded successfully!\")\n",
        "\n",
        "    # Dataset\n",
        "    dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)\n",
        "    kf_3d = None\n",
        "\n",
        "    # Process video\n",
        "    for frame_idx, (path, im, im0s, vid_cap, s) in enumerate(dataset):\n",
        "        print(f\"Processing frame {frame_idx}\")\n",
        "\n",
        "        if frame_height is None:\n",
        "            frame_height = im0s.shape[0]\n",
        "\n",
        "        # Estimate depth map\n",
        "        depth_map = depth_estimator.estimate_depth(im0s)\n",
        "\n",
        "        # Preprocess for object detection\n",
        "        im = torch.from_numpy(im).to(device)\n",
        "        im = im.half() if half else im.float()\n",
        "        im /= 255\n",
        "        if len(im.shape) == 3:\n",
        "            im = im[None]\n",
        "\n",
        "        # Inference\n",
        "        pred = model(im)\n",
        "        pred = non_max_suppression(pred, conf_thres, iou_thres, None, False, max_det=max_det)\n",
        "\n",
        "        # Process detections\n",
        "        det = pred[0]\n",
        "        current_point_3d = None\n",
        "\n",
        "        if len(det):\n",
        "            # Rescale boxes to original image\n",
        "            det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0s.shape).round()\n",
        "            # Get center of first detection\n",
        "            *xyxy, conf, cls = det[0]\n",
        "            cx = int((xyxy[0] + xyxy[2]) / 2)\n",
        "            cy = int((xyxy[1] + xyxy[3]) / 2)\n",
        "\n",
        "            # Get depth at detection center\n",
        "            depth_value = depth_estimator.get_depth_at_point(depth_map, cx, cy)\n",
        "            # Convert depth to real-world units (scaled)\n",
        "            cz = depth_value / depth_scale\n",
        "\n",
        "            # Initialize or update 3D Kalman Filter\n",
        "            if kf_3d is None:\n",
        "                kf_3d = KalmanFilter3D(cx, cy, cz, g=g)\n",
        "                current_point_3d = (cx, cy, cz)\n",
        "            else:\n",
        "                # Predict before correction\n",
        "                kf_3d.predict()\n",
        "                kf_3d.correct(cx, cy, cz)\n",
        "                current_point_3d = (int(kf_3d.state[0]), int(kf_3d.state[1]), kf_3d.state[2])\n",
        "\n",
        "        # Handle no detection with existing KF\n",
        "        elif kf_3d is not None:\n",
        "            px, py, pz = kf_3d.predict()\n",
        "            current_point_3d = (int(px), int(py), pz)\n",
        "\n",
        "        # Store actual trajectory point\n",
        "        if current_point_3d:\n",
        "            actual_trajectory_3d.append(current_point_3d)\n",
        "        else:\n",
        "            actual_trajectory_3d.append(None)\n",
        "\n",
        "        # Trigger full 3D prediction at specified frame\n",
        "        if frame_idx == early_pred_frame and kf_3d is not None and not triggered:\n",
        "            triggered = True\n",
        "            x0, y0, z0, vx0, vy0, vz0 = kf_3d.state\n",
        "            # Simulate 3D trajectory until ball hits bottom of frame\n",
        "            for t in range(100):  # Max 100 frames prediction\n",
        "                x = x0 + vx0 * t\n",
        "                y = y0 + vy0 * t + 0.5 * g * t**2\n",
        "                z = z0 + vz0 * t\n",
        "                # Stop when ball hits ground\n",
        "                if y >= frame_height - 5:  # 5px buffer\n",
        "                    break\n",
        "                predicted_full_trajectory_3d.append((int(x), int(y), z))\n",
        "\n",
        "    # Save trajectory data\n",
        "    trajectory_data = {\n",
        "        'actual_3d': actual_trajectory_3d,\n",
        "        'predicted_full_3d': predicted_full_trajectory_3d,\n",
        "        'trigger_frame': early_pred_frame,\n",
        "        'frame_height': frame_height,\n",
        "        'depth_scale': depth_scale\n",
        "    }\n",
        "    with open(str(save_dir / 'trajectory_data_3d.json'), 'w') as f:\n",
        "        json.dump(trajectory_data, f, default=str)  # Handle numpy types\n",
        "\n",
        "    # Generate and save 3D plot\n",
        "    plot_trajectory_3d(actual_trajectory_3d, predicted_full_trajectory_3d, frame_height, save_dir)\n",
        "\n",
        "    print(f\"Results saved to {save_dir}\")\n",
        "\n",
        "def plot_trajectory_3d(actual, predicted, frame_height, save_dir):\n",
        "    fig = plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # 3D plot\n",
        "    ax1 = fig.add_subplot(221, projection='3d')\n",
        "\n",
        "    # Process actual trajectory\n",
        "    actual_points = [p for p in actual if p is not None]\n",
        "    if actual_points:\n",
        "        actual_x = [p[0] for p in actual_points]\n",
        "        actual_y = [frame_height - p[1] for p in actual_points]  # Flip Y for display\n",
        "        actual_z = [p[2] for p in actual_points]\n",
        "\n",
        "        ax1.plot(actual_x, actual_z, actual_y, 'go-', linewidth=2, markersize=4, label='Actual 3D Trajectory')\n",
        "\n",
        "    # Process predicted trajectory\n",
        "    if predicted:\n",
        "        pred_x = [p[0] for p in predicted]\n",
        "        pred_y = [frame_height - p[1] for p in predicted]  # Flip Y for display\n",
        "        pred_z = [p[2] for p in predicted]\n",
        "\n",
        "        ax1.plot(pred_x, pred_z, pred_y, 'r--', linewidth=2, label='Predicted 3D Trajectory')\n",
        "\n",
        "    # Mark trigger point\n",
        "    if actual_points and len(actual_points) > 10:\n",
        "        trigger_point = actual_points[10]\n",
        "        ax1.scatter([trigger_point[0]], [trigger_point[2]], [frame_height - trigger_point[1]],\n",
        "                   c='blue', s=100, label='Prediction Trigger')\n",
        "\n",
        "    ax1.set_xlabel('X Position (pixels)')\n",
        "    ax1.set_ylabel('Z Position (depth units)')\n",
        "    ax1.set_zlabel('Height from Bottom (pixels)')\n",
        "    ax1.set_title('3D Ball Trajectory Prediction')\n",
        "    ax1.legend()\n",
        "\n",
        "    # XY projection\n",
        "    ax2 = fig.add_subplot(222)\n",
        "    if actual_points:\n",
        "        ax2.plot(actual_x, actual_y, 'go-', linewidth=2, markersize=4, label='Actual XY')\n",
        "    if predicted:\n",
        "        ax2.plot(pred_x, pred_y, 'r--', linewidth=2, label='Predicted XY')\n",
        "    ax2.set_xlabel('X Position (pixels)')\n",
        "    ax2.set_ylabel('Height from Bottom (pixels)')\n",
        "    ax2.set_title('XY Projection')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    # XZ projection\n",
        "    ax3 = fig.add_subplot(223)\n",
        "    if actual_points:\n",
        "        ax3.plot(actual_x, actual_z, 'go-', linewidth=2, markersize=4, label='Actual XZ')\n",
        "    if predicted:\n",
        "        ax3.plot(pred_x, pred_z, 'r--', linewidth=2, label='Predicted XZ')\n",
        "    ax3.set_xlabel('X Position (pixels)')\n",
        "    ax3.set_ylabel('Z Position (depth units)')\n",
        "    ax3.set_title('XZ Projection')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True)\n",
        "\n",
        "    # YZ projection\n",
        "    ax4 = fig.add_subplot(224)\n",
        "    if actual_points:\n",
        "        ax4.plot(actual_z, actual_y, 'go-', linewidth=2, markersize=4, label='Actual YZ')\n",
        "    if predicted:\n",
        "        ax4.plot(pred_z, pred_y, 'r--', linewidth=2, label='Predicted YZ')\n",
        "    ax4.set_xlabel('Z Position (depth units)')\n",
        "    ax4.set_ylabel('Height from Bottom (pixels)')\n",
        "    ax4.set_title('YZ Projection')\n",
        "    ax4.legend()\n",
        "    ax4.grid(True)\n",
        "\n",
        "    # Save plot\n",
        "    plot_path = save_dir / 'trajectory_plot_3d.png'\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(str(plot_path), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"3D Trajectory plot saved to {plot_path}\")\n",
        "\n",
        "def parse_opt():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--weights', type=str, default='yolov5s.pt', help='model path')\n",
        "    parser.add_argument('--source', type=str, required=True, help='video file path')\n",
        "    parser.add_argument('--data', type=str, default='data/coco128.yaml', help='dataset.yaml path')\n",
        "    parser.add_argument('--imgsz', '--img-size', nargs='+', type=int, default=[640], help='inference size')\n",
        "    parser.add_argument('--conf-thres', type=float, default=0.25, help='confidence threshold')\n",
        "    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS IoU threshold')\n",
        "    parser.add_argument('--max-det', type=int, default=1000, help='maximum detections')\n",
        "    parser.add_argument('--device', default='', help='cuda device or cpu')\n",
        "    parser.add_argument('--project', default='runs/detect', help='save results to project')\n",
        "    parser.add_argument('--name', default='exp', help='save results to project/name')\n",
        "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok')\n",
        "    parser.add_argument('--half', action='store_true', help='use FP16 half-precision')\n",
        "    parser.add_argument('--dnn', action='store_true', help='use OpenCV DNN')\n",
        "    parser.add_argument('--g', type=float, default=0.5, help='gravity constant (pixels/frame^2)')\n",
        "    parser.add_argument('--early-pred-frame', type=int, default=10, help='frame to trigger prediction')\n",
        "    parser.add_argument('--depth-scale', type=float, default=1000.0, help='depth scaling factor')\n",
        "    opt = parser.parse_args()\n",
        "    opt.imgsz = opt.imgsz[0] if len(opt.imgsz) == 1 else opt.imgsz\n",
        "    return opt\n",
        "\n",
        "def main(opt):\n",
        "    run(\n",
        "        weights=opt.weights,\n",
        "        source=opt.source,\n",
        "        data=opt.data,\n",
        "        imgsz=opt.imgsz,\n",
        "        conf_thres=opt.conf_thres,\n",
        "        iou_thres=opt.iou_thres,\n",
        "        max_det=opt.max_det,\n",
        "        device=opt.device,\n",
        "        project=opt.project,\n",
        "        name=opt.name,\n",
        "        exist_ok=opt.exist_ok,\n",
        "        half=opt.half,\n",
        "        dnn=opt.dnn,\n",
        "        g=opt.g,\n",
        "        early_pred_frame=opt.early_pred_frame,\n",
        "        depth_scale=opt.depth_scale\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    opt = parse_opt()\n",
        "    main(opt)"
      ],
      "metadata": {
        "id": "LINAbR8EbF-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3D kalman filter trajectory code with depth estimation using Depth Anything V2\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from models.common import DetectMultiBackend\n",
        "from utils.dataloaders import LoadImages\n",
        "from utils.general import (check_img_size, non_max_suppression, xyxy2xywh, increment_path)\n",
        "from utils.torch_utils import select_device\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from models.common import DetectMultiBackend\n",
        "from utils.dataloaders import LoadImages\n",
        "from utils.general import (check_img_size, non_max_suppression, xyxy2xywh, increment_path)\n",
        "from utils.torch_utils import select_device\n",
        "\n",
        "class DepthAnythingV2Estimator:\n",
        "    def __init__(self, model_size='small'):\n",
        "        self.model_size = model_size\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model_configs = {\n",
        "            'small': 'depth-anything/Depth-Anything-V2-Small-hf',\n",
        "            'base': 'depth-anything/Depth-Anything-V2-Base-hf',\n",
        "            'large': 'depth-anything/Depth-Anything-V2-Large-hf'\n",
        "        }\n",
        "        try:\n",
        "            from transformers import pipeline\n",
        "            model_name = self.model_configs.get(model_size, self.model_configs['base'])\n",
        "            print(f\"Loading Depth Anything V2 {model_size} model...\")\n",
        "            self.pipe = pipeline(\n",
        "                task=\"depth-estimation\",\n",
        "                model=model_name,\n",
        "                device=0 if torch.cuda.is_available() else -1\n",
        "            )\n",
        "            self.method = f'depth_anything_v2_{model_size}'\n",
        "            print(f\"Depth Anything V2 {model_size} loaded successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load Depth Anything V2: {e}\")\n",
        "            self.pipe = None\n",
        "            self.method = 'simple'\n",
        "\n",
        "    def preprocess_image(self, image):\n",
        "        if isinstance(image, np.ndarray):\n",
        "            if len(image.shape) == 3 and image.shape[2] == 3:\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            image = Image.fromarray(image.astype(np.uint8))\n",
        "        return image\n",
        "\n",
        "    def estimate_depth(self, frame, bbox=None):\n",
        "        if self.pipe is not None:\n",
        "            try:\n",
        "                image = self.preprocess_image(frame)\n",
        "                result = self.pipe(image)\n",
        "                depth_map = np.array(result['depth'])\n",
        "                depth_map = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())\n",
        "                depth_map = depth_map * 255\n",
        "\n",
        "                if bbox is not None:\n",
        "                    x1, y1, x2, y2 = map(int, bbox)\n",
        "                    h, w = depth_map.shape[:2]\n",
        "                    x1, y1 = max(0, x1), max(0, y1)\n",
        "                    x2, y2 = min(w, x2), min(h, y2)\n",
        "                    if x2 > x1 and y2 > y1:\n",
        "                        roi_depth = depth_map[y1:y2, x1:x2]\n",
        "                        if roi_depth.size > 0:\n",
        "                            median_depth = float(np.median(roi_depth))\n",
        "                            depth_distance = max(10.0, min(500.0, 300.0 - median_depth))\n",
        "                            return depth_distance\n",
        "                    return 100.0\n",
        "\n",
        "                return depth_map\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Depth estimation failed: {e}\")\n",
        "                return 100.0\n",
        "        else:\n",
        "            return 100.0\n",
        "\n",
        "class KalmanFilter3D:\n",
        "    def __init__(self, x, y, z, dt=1.0, g=0.5):\n",
        "        self.dt = dt\n",
        "        self.g = g\n",
        "        self.state = np.array([x, y, z, 0, 0, 0], dtype=np.float32)\n",
        "        self.F = np.array([\n",
        "            [1, 0, 0, dt, 0, 0],\n",
        "            [0, 1, 0, 0, dt, 0],\n",
        "            [0, 0, 1, 0, 0, dt],\n",
        "            [0, 0, 0, 1, 0, 0],\n",
        "            [0, 0, 0, 0, 1, 0],\n",
        "            [0, 0, 0, 0, 0, 1]\n",
        "        ], dtype=np.float32)\n",
        "        self.H = np.eye(3, 6, dtype=np.float32)\n",
        "        self.Q = np.eye(6, dtype=np.float32) * 0.01\n",
        "        self.R = np.diag([10, 10, 50]).astype(np.float32)\n",
        "        self.P = np.eye(6, dtype=np.float32) * 100\n",
        "\n",
        "    def predict(self):\n",
        "        self.state = self.F @ self.state\n",
        "        self.state[1] += 0.5 * self.g * self.dt**2\n",
        "        self.state[4] += self.g * self.dt\n",
        "        self.P = self.F @ self.P @ self.F.T + self.Q\n",
        "        return self.state[0], self.state[1], self.state[2]\n",
        "\n",
        "    def correct(self, x, y, z):\n",
        "        z_measure = np.array([x, y, z], dtype=np.float32)\n",
        "        y_residual = z_measure - self.H @ self.state\n",
        "        S = self.H @ self.P @ self.H.T + self.R\n",
        "        K = self.P @ self.H.T @ np.linalg.inv(S)\n",
        "        self.state = self.state + K @ y_residual\n",
        "        I = np.eye(6, dtype=np.float32)\n",
        "        self.P = (I - K @ self.H) @ self.P\n",
        "\n",
        "def plot_trajectory_3d(actual, predicted, frame_height, save_dir):\n",
        "    fig = plt.figure(figsize=(15, 10))\n",
        "    ax1 = fig.add_subplot(221, projection='3d')\n",
        "    actual_points = [p for p in actual if p is not None]\n",
        "    if actual_points:\n",
        "        actual_x = [p[0] for p in actual_points]\n",
        "        actual_y = [frame_height - p[1] for p in actual_points]\n",
        "        actual_z = [p[2] for p in actual_points]\n",
        "        ax1.plot(actual_x, actual_z, actual_y, 'go-', linewidth=2, markersize=4, label='Actual 3D Trajectory')\n",
        "    if predicted:\n",
        "        pred_x = [p[0] for p in predicted]\n",
        "        pred_y = [frame_height - p[1] for p in predicted]\n",
        "        pred_z = [p[2] for p in predicted]\n",
        "        ax1.plot(pred_x, pred_z, pred_y, 'r--', linewidth=2, label='Predicted 3D Trajectory')\n",
        "    ax1.set_xlabel('X Position (pixels)')\n",
        "    ax1.set_ylabel('Z Position (depth units)')\n",
        "    ax1.set_zlabel('Height from Bottom (pixels)')\n",
        "    ax1.set_title('3D Ball Trajectory Prediction')\n",
        "    ax1.legend()\n",
        "    ax2 = fig.add_subplot(222)\n",
        "    if actual_points:\n",
        "        ax2.plot(actual_x, actual_y, 'go-', linewidth=2, markersize=4, label='Actual XY')\n",
        "    if predicted:\n",
        "        ax2.plot(pred_x, pred_y, 'r--', linewidth=2, label='Predicted XY')\n",
        "    ax2.set_xlabel('X Position (pixels)')\n",
        "    ax2.set_ylabel('Height from Bottom (pixels)')\n",
        "    ax2.set_title('XY Projection')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "    ax3 = fig.add_subplot(223)\n",
        "    if actual_points:\n",
        "        ax3.plot(actual_x, actual_z, 'go-', linewidth=2, markersize=4, label='Actual XZ')\n",
        "    if predicted:\n",
        "        ax3.plot(pred_x, pred_z, 'r--', linewidth=2, label='Predicted XZ')\n",
        "    ax3.set_xlabel('X Position (pixels)')\n",
        "    ax3.set_ylabel('Z Position (depth units)')\n",
        "    ax3.set_title('XZ Projection')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True)\n",
        "    ax4 = fig.add_subplot(224)\n",
        "    if actual_points:\n",
        "        ax4.plot(actual_z, actual_y, 'go-', linewidth=2, markersize=4, label='Actual YZ')\n",
        "    if predicted:\n",
        "        ax4.plot(pred_z, pred_y, 'r--', linewidth=2, label='Predicted YZ')\n",
        "    ax4.set_xlabel('Z Position (depth units)')\n",
        "    ax4.set_ylabel('Height from Bottom (pixels)')\n",
        "    ax4.set_title('YZ Projection')\n",
        "    ax4.legend()\n",
        "    ax4.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(str(save_dir / 'trajectory_plot_3d.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"3D Trajectory plot saved to {save_dir / 'trajectory_plot_3d.png'}\")\n",
        "\n",
        "def run(weights, source, data, imgsz, conf_thres, iou_thres, max_det, device, project, name, exist_ok, half, dnn, g, early_pred_frame):\n",
        "    source = str(source)\n",
        "    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    actual_trajectory_3d = []\n",
        "    predicted_full_trajectory_3d = []\n",
        "    frame_height = None\n",
        "    triggered = False\n",
        "\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
        "    stride, names, pt = model.stride, model.names, model.pt\n",
        "    imgsz = check_img_size(imgsz, s=stride)\n",
        "\n",
        "    depth_estimator = DepthAnythingV2Estimator(model_size='small')\n",
        "\n",
        "    dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)\n",
        "    kf_3d = None\n",
        "\n",
        "    for frame_idx, (path, im, im0s, vid_cap, s) in enumerate(dataset):\n",
        "        print(f\"Processing frame {frame_idx}\")\n",
        "        if frame_height is None:\n",
        "            frame_height = im0s.shape[0]\n",
        "\n",
        "        im = torch.from_numpy(im).to(device)\n",
        "        im = im.half() if half else im.float()\n",
        "        im /= 255\n",
        "        if len(im.shape) == 3:\n",
        "            im = im[None]\n",
        "\n",
        "        pred = model(im)\n",
        "        pred = non_max_suppression(pred, conf_thres, iou_thres, None, False, max_det=max_det)\n",
        "\n",
        "        det = pred[0]\n",
        "        current_point_3d = None\n",
        "\n",
        "        if len(det):\n",
        "            det[:, :4] = det[:, :4].round()\n",
        "            *xyxy, conf, cls = det[0]\n",
        "            cx = int((xyxy[0] + xyxy[2]) / 2)\n",
        "            cy = int((xyxy[1] + xyxy[3]) / 2)\n",
        "            bbox = (int(xyxy[0]), int(xyxy[1]), int(xyxy[2]), int(xyxy[3]))\n",
        "            cz = depth_estimator.estimate_depth(im0s, bbox)\n",
        "\n",
        "            if kf_3d is None:\n",
        "                kf_3d = KalmanFilter3D(cx, cy, cz, g=g)\n",
        "                current_point_3d = (cx, cy, cz)\n",
        "            else:\n",
        "                kf_3d.predict()\n",
        "                kf_3d.correct(cx, cy, cz)\n",
        "                current_point_3d = (int(kf_3d.state[0]), int(kf_3d.state[1]), kf_3d.state[2])\n",
        "\n",
        "        elif kf_3d is not None:\n",
        "            px, py, pz = kf_3d.predict()\n",
        "            current_point_3d = (int(px), int(py), pz)\n",
        "\n",
        "        if current_point_3d:\n",
        "            actual_trajectory_3d.append(current_point_3d)\n",
        "        else:\n",
        "            actual_trajectory_3d.append(None)\n",
        "\n",
        "        if frame_idx == early_pred_frame and kf_3d is not None and not triggered:\n",
        "            triggered = True\n",
        "            x0, y0, z0, vx0, vy0, vz0 = kf_3d.state\n",
        "            for t in range(100):\n",
        "                x = x0 + vx0 * t\n",
        "                y = y0 + vy0 * t + 0.5 * g * t**2\n",
        "                z = z0 + vz0 * t\n",
        "                if y >= frame_height - 5:\n",
        "                    break\n",
        "                predicted_full_trajectory_3d.append((int(x), int(y), z))\n",
        "\n",
        "    with open(str(save_dir / 'trajectory_data_3d.json'), 'w') as f:\n",
        "        json.dump({\n",
        "            'actual_3d': actual_trajectory_3d,\n",
        "            'predicted_full_3d': predicted_full_trajectory_3d,\n",
        "            'trigger_frame': early_pred_frame,\n",
        "            'frame_height': frame_height\n",
        "        }, f, default=str)\n",
        "\n",
        "    plot_trajectory_3d(actual_trajectory_3d, predicted_full_trajectory_3d, frame_height, save_dir)\n",
        "    print(f\"Results saved to {save_dir}\")\n",
        "\n",
        "def parse_opt():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--weights', type=str, default='yolov5s.pt')\n",
        "    parser.add_argument('--source', type=str, required=True)\n",
        "    parser.add_argument('--data', type=str, default='data/coco128.yaml')\n",
        "    parser.add_argument('--imgsz', nargs='+', type=int, default=[640])\n",
        "    parser.add_argument('--conf-thres', type=float, default=0.25)\n",
        "    parser.add_argument('--iou-thres', type=float, default=0.45)\n",
        "    parser.add_argument('--max-det', type=int, default=1000)\n",
        "    parser.add_argument('--device', default='')\n",
        "    parser.add_argument('--project', default='runs/detect')\n",
        "    parser.add_argument('--name', default='exp')\n",
        "    parser.add_argument('--exist-ok', action='store_true')\n",
        "    parser.add_argument('--half', action='store_true')\n",
        "    parser.add_argument('--dnn', action='store_true')\n",
        "    parser.add_argument('--g', type=float, default=0.5)\n",
        "    parser.add_argument('--early-pred-frame', type=int, default=10)\n",
        "    opt = parser.parse_args()\n",
        "    opt.imgsz = opt.imgsz[0] if len(opt.imgsz) == 1 else opt.imgsz\n",
        "    return opt\n",
        "\n",
        "def main(opt):\n",
        "    run(**vars(opt))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    opt = parse_opt()\n",
        "    main(opt)\n"
      ],
      "metadata": {
        "id": "XrNxh2mtbP0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py \\\n",
        "--weights /content/drive/MyDrive/test_model/best030422.pt \\\n",
        "--source /content/drive/MyDrive/test_model/t4.mp4 \\\n",
        "--project /content/drive/MyDrive/Finalresults \\\n",
        "--name trajectory_results4 \\\n",
        "--conf-thres 0.3 \\\n",
        "--early-pred-frame 10 \\\n",
        "--device cpu"
      ],
      "metadata": {
        "id": "IJqIM25ybbdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7DVjUGqkbkS9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}